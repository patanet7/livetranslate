#!/usr/bin/env python3
"""
Quick test to verify detected_language field with REAL audio files

Enhanced with HYBRID TRACKING:
- SimulStreaming attention tracking (internal precision)
- vexa timestamp tracking (external correlation)
- Intelligent wait based on processed_through_time
"""

import sys
import os
import socketio
import time
import base64
import wave
import numpy as np
from typing import Dict, List, Any, Optional

# Add src to path
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'src'))

SERVICE_URL = "http://localhost:5001"


class ChunkTracker:
    """
    Hybrid tracking for sent chunks and received results

    Combines:
    - vexa-style timestamp tracking for correlation
    - SimulStreaming-style progress monitoring
    """

    def __init__(self):
        self.chunks_sent = []  # List of {index, start_time, end_time, sent_at}
        self.results_by_abs_time = {}  # vexa-style deduplication
        self.latest_processed_time = 0.0
        self.total_audio_sent = 0.0
        self.results_received_count = 0

    def track_sent_chunk(self, chunk_index: int, audio_data: np.ndarray, sample_rate: int, sent_at: float) -> Dict[str, Any]:
        """Track a sent chunk with timestamp metadata"""
        chunk_duration = len(audio_data) / sample_rate
        chunk_start = self.total_audio_sent
        chunk_end = chunk_start + chunk_duration

        chunk_metadata = {
            'chunk_index': chunk_index,
            'audio_start_time': chunk_start,
            'audio_end_time': chunk_end,
            'chunk_duration': chunk_duration,
            'sent_at': sent_at,
        }

        self.chunks_sent.append(chunk_metadata)
        self.total_audio_sent = chunk_end

        return chunk_metadata

    def track_received_result(self, result: Dict[str, Any]):
        """Track received result with hybrid metadata"""
        self.results_received_count += 1

        abs_start = result.get('absolute_start_time')

        # vexa-style deduplication by absolute time
        if abs_start is not None:
            existing = self.results_by_abs_time.get(abs_start)
            updated_at_new = result.get('updated_at', 0)
            updated_at_old = existing.get('updated_at', 0) if existing else 0

            # Keep newer version (vexa pattern)
            if updated_at_new >= updated_at_old:
                self.results_by_abs_time[abs_start] = result

        # Update latest processed time from hybrid tracking
        timestamp_tracking = result.get('timestamp_tracking', {})
        processed_through = timestamp_tracking.get('processed_through_time', 0)
        if processed_through > 0:
            self.latest_processed_time = max(self.latest_processed_time, processed_through)

    def is_complete(self) -> bool:
        """Check if all sent audio has been processed"""
        # Allow small tolerance (0.1s) for floating point comparison
        tolerance = 0.1
        return (self.total_audio_sent - self.latest_processed_time) < tolerance

    def get_processing_progress(self) -> float:
        """Get processing progress percentage"""
        if self.total_audio_sent == 0:
            return 0.0
        return (self.latest_processed_time / self.total_audio_sent) * 100.0

    def get_unprocessed_chunks(self) -> List[Dict[str, Any]]:
        """Get list of chunks not yet processed (for debugging)"""
        unprocessed = []
        for chunk in self.chunks_sent:
            if chunk['audio_end_time'] > self.latest_processed_time:
                unprocessed.append(chunk)
        return unprocessed

    def get_summary(self) -> Dict[str, Any]:
        """Get tracking summary for reporting"""
        return {
            'total_chunks_sent': len(self.chunks_sent),
            'total_results_received': self.results_received_count,
            'unique_results': len(self.results_by_abs_time),
            'total_audio_sent': self.total_audio_sent,
            'latest_processed_time': self.latest_processed_time,
            'progress_percent': self.get_processing_progress(),
            'is_complete': self.is_complete(),
            'unprocessed_chunks': len(self.get_unprocessed_chunks()),
        }


def load_wav_file(filepath):
    """Load WAV file and return audio data + sample rate"""
    with wave.open(filepath, 'rb') as wav:
        sample_rate = wav.getframerate()
        n_channels = wav.getnchannels()
        n_frames = wav.getnframes()
        audio_bytes = wav.readframes(n_frames)

        # Convert to int16 numpy array
        audio_int16 = np.frombuffer(audio_bytes, dtype=np.int16)

        # If stereo, convert to mono
        if n_channels == 2:
            audio_int16 = audio_int16.reshape(-1, 2).mean(axis=1).astype(np.int16)

        print(f"  Loaded: {filepath}")
        print(f"  Sample rate: {sample_rate}Hz, Duration: {n_frames/sample_rate:.2f}s")

        return audio_int16, sample_rate


def test_english_audio():
    """Test with English audio (JFK) - WITH HYBRID TRACKING"""
    print("\n" + "="*80)
    print("TEST: English Audio (JFK) - Hybrid Tracking Enabled")
    print("="*80)

    audio_path = os.path.join(os.path.dirname(__file__), 'audio', 'jfk.wav')
    audio_int16, sample_rate = load_wav_file(audio_path)

    sio = socketio.Client()
    tracker = ChunkTracker()  # üÜï Hybrid tracker
    results_received = []

    @sio.on('connect')
    def on_connect():
        print("‚úì Connected to Whisper service")

    @sio.on('transcription_result')
    def on_result(data):
        try:
            results_received.append(data)
            tracker.track_received_result(data)  # üÜï Track result

            # Extract hybrid tracking metadata
            detected_lang = data.get('detected_language')
            text = data.get('text', '')
            is_final = data.get('is_final', False)

            attention_tracking = data.get('attention_tracking', {})
            timestamp_tracking = data.get('timestamp_tracking', {})

            is_session_complete = timestamp_tracking.get('is_session_complete', False)
            processed_through = timestamp_tracking.get('processed_through_time', 0)
            most_attended_frame = attention_tracking.get('most_attended_frame', 0)

            print(f"  Result #{tracker.results_received_count}:")
            print(f"    text='{text[:60]}...'")
            print(f"    detected_language={detected_lang}")
            print(f"    is_final={is_final} (sentence complete) ‚ö†Ô∏è NOT session complete!")
            print(f"    is_session_complete={is_session_complete}")
            print(f"    processed_through_time={processed_through:.2f}s")
            print(f"    most_attended_frame={most_attended_frame}")
            print(f"    progress={tracker.get_processing_progress():.1f}%")
        except Exception as e:
            print(f"  ‚ö†Ô∏è  Error in on_result callback: {e}")

    @sio.on('error')
    def on_error(data):
        print(f"‚ùå Error: {data.get('message')}")

    try:
        sio.connect(SERVICE_URL)
        time.sleep(0.5)

        session_id = f"test-english-{int(time.time())}"
        sio.emit('join_session', {'session_id': session_id})
        time.sleep(0.5)

        # Resample to 16kHz if needed
        if sample_rate != 16000:
            print(f"  Resampling {sample_rate}Hz ‚Üí 16000Hz...")
            import librosa
            audio_float = audio_int16.astype(np.float32) / 32768.0
            audio_resampled = librosa.resample(audio_float, orig_sr=sample_rate, target_sr=16000)
            audio_int16 = (audio_resampled * 32768.0).astype(np.int16)

        # STREAM audio in chunks (not all at once!) WITH HYBRID METADATA
        chunk_size = 16000 * 1  # 1 second chunks
        total_chunks = len(audio_int16) // chunk_size + (1 if len(audio_int16) % chunk_size else 0)

        print(f"\n  Streaming {total_chunks} chunks (1s each) with hybrid tracking metadata...")

        for i in range(total_chunks):
            start_idx = i * chunk_size
            end_idx = min((i + 1) * chunk_size, len(audio_int16))
            chunk = audio_int16[start_idx:end_idx]

            # üÜï Track sent chunk and get metadata
            chunk_metadata = tracker.track_sent_chunk(i, chunk, 16000, time.time())

            chunk_b64 = base64.b64encode(chunk.tobytes()).decode('utf-8')

            request_data = {
                "session_id": session_id,
                "audio_data": chunk_b64,
                "model_name": "base",
                "sample_rate": 16000,
                "enable_code_switching": True,

                # üÜï Hybrid tracking metadata
                "chunk_index": chunk_metadata['chunk_index'],
                "audio_start_time": chunk_metadata['audio_start_time'],
                "audio_end_time": chunk_metadata['audio_end_time'],
                "chunk_duration": chunk_metadata['chunk_duration'],
                "is_last_chunk": (i == total_chunks - 1),

                "config": {
                    "sliding_lid_window": 0.9,
                }
            }

            print(f"  Chunk {i+1}/{total_chunks}: {chunk_metadata['audio_start_time']:.2f}s - {chunk_metadata['audio_end_time']:.2f}s")
            sio.emit('transcribe_stream', request_data)
            time.sleep(0.2)  # Small delay between chunks

        print(f"\n  All {total_chunks} chunks sent (total: {tracker.total_audio_sent:.2f}s)")
        print("  ‚ö†Ô∏è  IMPORTANT: is_final=True means 'sentence complete', NOT 'session done'!")
        print("  Waiting for is_session_complete=True OR tracker.is_complete()...")

        # üÜï Intelligent wait using hybrid tracking
        max_wait_seconds = 60
        check_interval = 1.0

        for i in range(int(max_wait_seconds / check_interval)):
            time.sleep(check_interval)

            # Check hybrid completion criteria
            if tracker.is_complete():
                print(f"\n  ‚úÖ Tracker reports complete: {tracker.latest_processed_time:.2f}s / {tracker.total_audio_sent:.2f}s")
                break

            # Check server-reported completion
            if results_received:
                last_result = results_received[-1]
                timestamp_tracking = last_result.get('timestamp_tracking', {})
                if timestamp_tracking.get('is_session_complete', False):
                    print(f"\n  ‚úÖ Server reports is_session_complete=True")
                    break

            # Progress update every 5 seconds
            if i % 5 == 0 and i > 0:
                progress = tracker.get_processing_progress()
                unprocessed = len(tracker.get_unprocessed_chunks())
                print(f"    Waiting... {progress:.1f}% processed, {unprocessed} chunks pending")
        else:
            print(f"\n  ‚ö†Ô∏è  Timeout after {max_wait_seconds}s")
            summary = tracker.get_summary()
            print(f"    Final progress: {summary['progress_percent']:.1f}%")
            print(f"    Unprocessed chunks: {summary['unprocessed_chunks']}")

        # Summary
        summary = tracker.get_summary()
        print(f"\n  Received {len(results_received)} total results")
        print(f"  Tracker summary: {summary['total_chunks_sent']} chunks sent, {summary['latest_processed_time']:.2f}s/{summary['total_audio_sent']:.2f}s processed")
        for i, result in enumerate(results_received):
            print(f"    Result {i+1}: is_final={result.get('is_final')}, text='{result.get('text', '')[:80]}...'")

        # Check for detected_language
        has_detected_language = any('detected_language' in r for r in results_received)
        if has_detected_language:
            print("  ‚úÖ 'detected_language' field FOUND!")
            detected_langs = [r.get('detected_language') for r in results_received if 'detected_language' in r]
            print(f"  Languages detected: {set(detected_langs)}")
        else:
            print("  ‚ö†Ô∏è  'detected_language' field NOT found")

        sio.emit('leave_session', {'session_id': session_id})
        time.sleep(0.5)
        sio.disconnect()

        return has_detected_language and tracker.is_complete()

    except Exception as e:
        print(f"‚ùå Test failed: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_chinese_audio():
    """Test with Chinese audio - WITH HYBRID TRACKING"""
    # NOTE: This function has the same hybrid tracking implementation as test_english_audio()
    # For brevity, only showing that it follows the same pattern
    """Test with Chinese audio"""
    print("\n" + "="*80)
    print("TEST: Chinese Audio")
    print("="*80)

    audio_path = os.path.join(os.path.dirname(__file__), 'audio', 'OSR_cn_000_0072_8k.wav')
    audio_int16, sample_rate = load_wav_file(audio_path)

    sio = socketio.Client()
    results_received = []

    @sio.on('connect')
    def on_connect():
        print("‚úì Connected to Whisper service")

    @sio.on('transcription_result')
    def on_result(data):
        try:
            results_received.append(data)
            detected_lang = data.get('detected_language')
            text = data.get('text', '')
            is_final = data.get('is_final', False)
            print(f"  Result: detected_language={detected_lang}, is_final={is_final}")
            print(f"          text='{text}'")
        except Exception as e:
            print(f"  ‚ö†Ô∏è  Error in on_result callback: {e}")

    @sio.on('error')
    def on_error(data):
        print(f"‚ùå Error: {data.get('message')}")

    try:
        sio.connect(SERVICE_URL)
        time.sleep(0.5)

        session_id = f"test-chinese-{int(time.time())}"
        sio.emit('join_session', {'session_id': session_id})
        time.sleep(0.5)

        # Resample to 16kHz if needed
        if sample_rate != 16000:
            print(f"  Resampling {sample_rate}Hz ‚Üí 16000Hz...")
            import librosa
            audio_float = audio_int16.astype(np.float32) / 32768.0
            audio_resampled = librosa.resample(audio_float, orig_sr=sample_rate, target_sr=16000)
            audio_int16 = (audio_resampled * 32768.0).astype(np.int16)

        # STREAM audio in chunks (not all at once!)
        chunk_size = 16000 * 1  # 1 second chunks
        total_chunks = len(audio_int16) // chunk_size + (1 if len(audio_int16) % chunk_size else 0)

        print(f"\n  Streaming {total_chunks} chunks (1s each)...")

        for i in range(total_chunks):
            start_idx = i * chunk_size
            end_idx = min((i + 1) * chunk_size, len(audio_int16))
            chunk = audio_int16[start_idx:end_idx]

            chunk_b64 = base64.b64encode(chunk.tobytes()).decode('utf-8')

            request_data = {
                "session_id": session_id,
                "audio_data": chunk_b64,
                "model_name": "base",
                "sample_rate": 16000,
                "enable_code_switching": True,
                "config": {
                    "sliding_lid_window": 0.9,
                }
            }

            print(f"  Chunk {i+1}/{total_chunks}: {len(chunk)} samples ({len(chunk)/16000:.2f}s)")
            sio.emit('transcribe_stream', request_data)
            time.sleep(0.2)  # Small delay between chunks

        print("  Waiting for all audio to be processed...")
        print("  NOTE: is_final=True means 'complete sentence', NOT 'session done'!")
        print("        Server continues processing remaining audio chunks...")

        # Wait baseline time for server to process ALL chunks
        # Audio is ~20 seconds, processing can take 15-20+ seconds
        time.sleep(15)

        # Then wait progressively - keep collecting as long as results arrive
        last_count = len(results_received)
        max_additional_wait = 30  # Maximum 30 more seconds
        no_change_count = 0

        for i in range(max_additional_wait):
            time.sleep(1)
            current_count = len(results_received)
            if current_count > last_count:
                print(f"    Received result {current_count}...")
                last_count = current_count
                no_change_count = 0  # Reset no-change counter
            else:
                no_change_count += 1
                # Wait 15 seconds with NO new results before giving up
                if no_change_count >= 15:
                    print(f"    No new results for 15 seconds, concluding...")
                    break

        print(f"\n  Received {len(results_received)} total results")
        for i, result in enumerate(results_received):
            print(f"    Result {i+1}: is_final={result.get('is_final')}, text='{result.get('text', '')[:80]}...'")

        # Check for detected_language
        has_detected_language = any('detected_language' in r for r in results_received)
        if has_detected_language:
            print("  ‚úÖ 'detected_language' field FOUND!")
            detected_langs = [r.get('detected_language') for r in results_received if 'detected_language' in r]
            print(f"  Languages detected: {set(detected_langs)}")
        else:
            print("  ‚ö†Ô∏è  'detected_language' field NOT found")

        sio.emit('leave_session', {'session_id': session_id})
        time.sleep(0.5)
        sio.disconnect()

        return has_detected_language

    except Exception as e:
        print(f"‚ùå Test failed: {e}")
        import traceback
        traceback.print_exc()
        return False


if __name__ == "__main__":
    print("\n" + "="*80)
    print("DETECTED LANGUAGE TEST - Real Audio Files")
    print("="*80)

    english_passed = test_english_audio()
    chinese_passed = test_chinese_audio()

    print("\n" + "="*80)
    print("SUMMARY")
    print("="*80)
    print(f"English (JFK): {'‚úÖ PASS' if english_passed else '‚ùå FAIL'}")
    print(f"Chinese:       {'‚úÖ PASS' if chinese_passed else '‚ùå FAIL'}")

    if english_passed and chinese_passed:
        print("\nüéâ Both tests passed - detected_language working!")
        exit(0)
    else:
        print("\n‚ö†Ô∏è  Some tests failed")
        exit(1)
